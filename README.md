# PSDE-Net: Dual Encoder Network with Parallel Strip Convolution for Road Extraction from Remote Sensing Images

![License](https://img.shields.io/badge/license-MIT-green)
![PyTorch](https://img.shields.io/badge/framework-PyTorch-blue)

**PSDE-Net** is a deep learning network designed for road extraction from remote sensing images. It addresses the challenges of accurately extracting road features, especially slender and winding roads, and ensuring road connectivity. The method incorporates a dual encoder structure and parallel strip convolutions, significantly improving road feature extraction and connectivity.<br>
**The corresponding paper is currently under review for publication in the journal _Computers and Geosciences_.**

## ğŸ” Overview

PSDE-Net is designed to enhance road extraction tasks, especially in the presence of complex, winding, and disconnected road networks. The model leverages two key innovations:
- __Dual Encoder Network:__ Integrates a ResNet-34 branch and a parallel strip convolution branch to extract multi-scale road features and capture long-range contextual information.
- __Road Connectivity Module (RCM):__ Utilizes graph convolution to improve the connectivity of extracted roads by inferring the spatial distribution of roads.

## ğŸš€ Key Features

- ğŸ“ **Strip Convolution Modules**: Extract directional and linear road features
- ğŸ **Dynamic Snake Convolutions**: Capture winding, narrow roads
- ğŸ§  **Graph Convolution Network**: Strengthen road connectivity

## ğŸ› ï¸ Installation

```bash
git clone https://github.com/ZhangHwwei/PSDE-Net.git
cd PSDE-Net

# (Optional) Create a conda virtual environment(Python 3.8 or later)
conda create -n psdenet python=3.8 -y
conda activate psdenet

# Install dependencies
pip install -r requirements.txt
```
## ğŸ“ Dataset
We use two publicly available datasets to evaluate the performance of PSDE-Net:
### 1. [DeepGlobe Road Extraction Dataset](http://deepglobe.org/challenge.html)
### 2. [CHN6-CUG Road Dataset](https://grzy.cug.edu.cn/zhuqiqi/zh_CN/yjgk/32368/list/index.htm)
> Please ensure your dataset is organized in the following directory structure:
```
dataset/
â”œâ”€â”€ DeepGlobe/
â”‚ â”œâ”€â”€ train/
â”‚ â”‚ â”œâ”€â”€ image/ # training images (e.g., .png or .jpg)
â”‚ â”‚ â””â”€â”€ label/ # corresponding binary masks
â”‚ â””â”€â”€ test/
â”‚ â”œâ”€â”€ image/ # test images
â”‚ â””â”€â”€ label/ # test masks
â”œâ”€â”€ CHN6-CUG/
â”‚ â”œâ”€â”€ train/
â”‚ â”‚ â”œâ”€â”€ image/
â”‚ â”‚ â””â”€â”€ label/
â”‚ â””â”€â”€ test/
â”‚ â”œâ”€â”€ image/
â”‚ â””â”€â”€ label/
```

## ğŸ“ˆ Training
```bash
python train_model.py
```
## ğŸ§ª Evaluation
```bash
python test_model.py
```
## ğŸ“ License
This project is licensed under the MIT License. See LICENSE for more information.
